{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/100/100-0.txt\n",
      "5783552/5777367 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
    "filepath = tf.keras.utils.get_file(fname='shakespeare.txt', origin=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = open(filepath, 'r', encoding='utf-8-sig').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = full_text[2771:101122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE SONNETS\\n\\n                    1\\n\\nFrom fairest creatures we desire increase,\\nThat thereby beauty’s rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\\nBut thou contracted to thine own bright eyes,\\nFeed’st thy light’s flame with self-substantial fuel,\\nMaking a famine where abundance lies,\\nThy self thy foe, to thy sweet self too cruel:\\nThou that art now the world’s fresh ornament,\\nAnd only herald to the gaudy spring,\\nWithin thine own bud buriest thy content,\\nAnd, tender churl, mak’st waste in niggarding:\\n  Pity the world, or else this glutton be,\\n  To eat the world’s due, by the grave and thee.\\n\\n\\n                    2\\n\\nWhen forty winters shall besiege thy brow,\\nAnd dig deep trenches in thy beauty’s field,\\nThy youth’s proud livery so gazed on now,\\nWill be a tattered weed of small worth held:\\nThen being asked, where all thy beauty lies,\\nWhere all the treasure of thy lusty days;\\nTo say, within thine own deep sunken eyes,\\nWere an all-eating shame, and thriftless praise.\\nHow much more praise deserv’d thy beauty’s use,\\nIf thou couldst answer ‘This fair child of mine\\nShall sum my count, and make my old excuse,’\\nProving his beauty by succession thine.\\n  This were to be new made when thou art old,\\n  And see thy blood warm when thou feel’st it cold.\\n\\n\\n                    3\\n\\nLook in thy glass and tell the face thou viewest,\\nNow is the time that face should form another,\\nWhose fresh repair if now thou not renewest,\\nThou dost beguile the world, unbless some mother.\\nFor where is she so fair whose uneared womb\\nDisdains the tillage of thy husbandry?\\nOr who is he so fond will be the tomb\\nOf his self-love to stop posterity?\\nThou art thy mother’s glass and she in thee\\nCalls back the lovely April of her prime,\\nSo thou through windows of thine age shalt see,\\nDespite of wrinkles this thy golden time.\\n  But if thou live remembered not to be,\\n  Die single and thine image dies with thee.\\n\\n\\n                    4\\n\\nUnthrifty loveliness why dost thou spend,\\nUpon thy self thy beauty’s legacy?\\nNature’s bequest gives nothing but doth lend,\\nAnd being frank she lends to those are free:\\nThen beauteous niggard why dost thou abuse,\\nThe bounteous largess given thee to give?\\nProfitless usurer why dost thou use\\nSo great a sum of sums yet canst not live?\\nFor having traffic with thy self alone,\\nThou of thy self thy sweet self dost deceive,\\nThen how when nature calls thee to be gone,\\nWhat acceptable audit canst thou leave?\\n  Thy unused beauty must be tombed with thee,\\n  Which used lives th’ executor to be.\\n\\n\\n                    5\\n\\nThose hours that with gentle work did frame\\nThe lovely gaze where every eye doth dwell\\nWill play the tyrants to the very same,\\nAnd that unfair which fairly doth excel:\\nFor never-resting time leads summer on\\nTo hideous winter and confounds him there,\\nSap checked with frost and lusty leaves quite gone,\\nBeauty o’er-snowed and bareness every where:\\nThen were not summer’s distillation left\\nA liquid prisoner pent in walls of glass,\\nBeauty’s effect with beauty were bereft,\\nNor it nor no remembrance what it was.\\n  But flowers distilled though they with winter meet,\\n  Leese but their show, their substance still lives sweet.\\n\\n\\n                    6\\n\\nThen let not winter’s ragged hand deface,\\nIn thee thy summer ere thou be distilled:\\nMake sweet some vial; treasure thou some place,\\nWith beauty’s treasure ere it be self-killed:\\nThat use is not forbidden usury,\\nWhich happies those that pay the willing loan;\\nThat’s for thy self to breed another thee,\\nOr ten times happier be it ten for one,\\nTen times thy self were happier than thou art,\\nIf ten of thine ten times refigured thee:\\nThen what could death do if thou shouldst depart,\\nLeaving thee living in posterity?\\n  Be not self-willed for thou art much too fair,\\n  To be death’s conquest and make worms thine heir.\\n\\n\\n                    7\\n\\nLo in the orient when the gracious light\\nLifts up his burning head, each under eye\\nDoth homage to his new-appearing sight,\\nServing with looks his sacred majesty,\\nAnd having climbed the steep-up heavenly hill,\\nResembling strong youth in his middle age,\\nYet mortal looks adore his beauty still,\\nAttending on his golden pilgrimage:\\nBut when from highmost pitch with weary car,\\nLike feeble age he reeleth from the day,\\nThe eyes (fore duteous) now converted are\\nFrom his low tract and look another way:\\n  So thou, thy self out-going in thy noon:\\n  Unlooked on diest unless thou get a son.\\n\\n\\n                    8\\n\\nMusic to hear, why hear’st thou music sadly?\\nSweets with sweets war not, joy delights in joy:\\nWhy lov’st thou that which thou receiv’st not gladly,\\nOr else receiv’st with pleasure thine annoy?\\nIf the true concord of well-tuned sounds,\\nBy unions married do offend thine ear,\\nThey do but sweetly chide thee, who confounds\\nIn singleness the parts that thou shouldst bear:\\nMark how one string sweet husband to another,\\nStrikes each in each by mutual ordering;\\nResembling sire, and child, and happy mother,\\nWho all in one, one pleasing note do sing:\\n  Whose speechless song being many, seeming one,\\n  Sings this to thee, ‘Thou single wilt prove none’.\\n\\n\\n                    9\\n\\nIs it for fear to wet a widow’s eye,\\nThat thou consum’st thy self in single life?\\nAh, if thou issueless shalt hap to die,\\nThe world will wail thee like a makeless wife,\\nThe world will be thy widow and still weep,\\nThat thou no form of thee hast left behind,\\nWhen every private widow well may keep,\\nBy children’s eyes, her husband’s shape in mind:\\nLook what an unthrift in the world doth spend\\nShifts but his place, for still the world enjoys it;\\nBut beauty’s waste hath in the world an end,\\nAnd kept unused the user so destroys it:\\n  No love toward others in that bosom sits\\n  That on himself such murd’rous shame commits.\\n\\n\\n                    10\\n\\nFor shame deny that thou bear’st love to any\\nWho for thy self art so unprovident.\\nGrant if thou wilt, thou art beloved of many,\\nBut that thou none lov’st is most evident:\\nFor thou art so possessed with murd’rous hate,\\nThat ’gainst thy self thou stick’st not to conspire,\\nSeeking that beauteous roof to ruinate\\nWhich to repair should be thy chief desire:\\nO change thy thought, that I may change my mind,\\nShall hate be fairer lodged than gentle love?\\nBe as thy presence is gracious and kind,\\nOr to thy self at least kind-hearted prove,\\n  Make thee another self for love of me,\\n  That beauty still may live in thine or thee.\\n\\n\\n                    11\\n\\nAs fast as thou shalt wane so fast thou grow’st,\\nIn one of thine, from that which thou departest,\\nAnd that fresh blood which youngly thou bestow’st,\\nThou mayst call thine, when thou from youth convertest,\\nHerein lives wisdom, beauty, and increase,\\nWithout this folly, age, and cold decay,\\nIf all were minded so, the times should cease,\\nAnd threescore year would make the world away:\\nLet those whom nature hath not made for store,\\nHarsh, featureless, and rude, barrenly perish:\\nLook whom she best endowed, she gave thee more;\\nWhich bounteous gift thou shouldst in bounty cherish:\\n  She carved thee for her seal, and meant thereby,\\n  Thou shouldst print more, not let that copy die.\\n\\n\\n                    12\\n\\nWhen I do count the clock that tells the time,\\nAnd see the brave day sunk in hideous night,\\nWhen I behold the violet past prime,\\nAnd sable curls all silvered o’er with white:\\nWhen lofty trees I see barren of leaves,\\nWhich erst from heat did canopy the herd\\nAnd summer’s green all girded up in sheaves\\nBorne on the bier with white and bristly beard:\\nThen of thy beauty do I question make\\nThat thou among the wastes of time must go,\\nSince sweets and beauties do themselves forsake,\\nAnd die as fast as they see others grow,\\n  And nothing ’gainst Time’s scythe can make defence\\n  Save breed to brave him, when he takes thee hence.\\n\\n\\n                    13\\n\\nO that you were your self, but love you are\\nNo longer yours, than you your self here live,\\nAgainst this coming end you should prepare,\\nAnd your sweet semblance to some other give.\\nSo should that beauty which you hold in lease\\nFind no determination, then you were\\nYour self again after your self’s decease,\\nWhen your sweet issue your sweet form should bear.\\nWho lets so fair a house fall to decay,\\nWhich husbandry in honour might uphold,\\nAgainst the stormy gusts of winter’s day\\nAnd barren rage of death’s eternal cold?\\n  O none but unthrifts, dear my love you know,\\n  You had a father, let your son say so.\\n\\n\\n                    14\\n\\nNot from the stars do I my judgement pluck,\\nAnd yet methinks I have astronomy,\\nBut not to tell of good, or evil luck,\\nOf plagues, of dearths, or seasons’ quality,\\nNor can I fortune to brief minutes tell;\\nPointing to each his thunder, rain and wind,\\nOr say with princes if it shall go well\\nBy oft predict that I in heaven find.\\nBut from thine eyes my knowledge I derive,\\nAnd constant stars in them I read such art\\nAs truth and beauty shall together thrive\\nIf from thy self, to store thou wouldst convert:\\n  Or else of thee this I prognosticate,\\n  Thy end is truth’s and beauty’s doom and date.\\n\\n\\n                    15\\n\\nWhen I consider every thing that grows\\nHolds in perfection but a little moment.\\nThat this huge stage presenteth nought but shows\\nWhereon the stars in secret influence comment.\\nWhen I perceive that men as plants increase,\\nCheered and checked even by the self-same sky:\\nVaunt in their youthful sap, at height decrease,\\nAnd wear their brave state out of memory.\\nThen the conceit of this inconstant stay,\\nSets you most rich in youth before my sight,\\nWhere wasteful time debateth with decay\\nTo change your day of youth to sullied night,\\n  And all in war with Time for love of you,\\n  As he takes from you, I engraft you new.\\n\\n\\n                    16\\n\\nBut wherefore do not you a mightier way\\nMake war upon this bloody tyrant Time?\\nAnd fortify your self in your decay\\nWith means more blessed than my barren rhyme?\\nNow stand you on the top of hap'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnets[0:9898]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def make_xy(text):\n",
    "    prep  = preprocess(text)\n",
    "    chars = sorted(set(text))\n",
    "    ' '.join(chars)\n",
    "    n_chars = len(text)\n",
    "    n_vocab = len(chars)\n",
    "    maxlen = 40\n",
    "    steps = 3\n",
    "\n",
    "    subsequences = [] # X \n",
    "    next_chars = [] # Y\n",
    "\n",
    "    for i in range(0, len(text) - maxlen, steps):\n",
    "        subsequences.append(text[i : i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "\n",
    "    x = np.zeros((len(subsequences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(subsequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "    for i, subsequence in enumerate(subsequences):\n",
    "        for t, char in enumerate(subsequence):\n",
    "            x[i, t, char_to_index[char]] = 1\n",
    "\n",
    "        y[i, char_to_index[next_chars[i]]] = 1\n",
    "        \n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = preprocess(sonnets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  ! ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P R S T U V W Y a b c d e f g h i j k l m n o p q r s t u v w x y z ‘ ’'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(set(sonnets))\n",
    "' '.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "char_to_index = {c:i for i, c in enumerate(chars)}\n",
    "index_to_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 94192\n",
      "Unique Characters: 71\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(sonnets)\n",
    "n_vocab = len(chars)\n",
    "print ('Total Characters:', n_chars)\n",
    "print ('Unique Characters:', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subsequences: 31384\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "steps = 3\n",
    "\n",
    "subsequences = [] # X \n",
    "next_chars = [] # Y\n",
    "\n",
    "for i in range(0, len(sonnets) - maxlen, steps):\n",
    "    subsequences.append(sonnets[i : i + maxlen])\n",
    "    next_chars.append(sonnets[i + maxlen])\n",
    "\n",
    "print ('Number of subsequences:', len(subsequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE SONNETS 1 From fairest creatures we '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify x & y.\n",
    "x = np.zeros((len(subsequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(subsequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, subsequence in enumerate(subsequences):\n",
    "    for t, char in enumerate(subsequence):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "        \n",
    "    y[i, char_to_index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31384, 40, 71)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Helper function to sample an index from a probability array.\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(sonnets) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        subsequence = sonnets[start_index: start_index + maxlen]\n",
    "        generated += subsequence\n",
    "        print('----- Generating with seed: \"' + subsequence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(subsequence):\n",
    "                x_pred[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = index_to_char[next_index]\n",
    "\n",
    "            subsequence = subsequence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7f3e1713a11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-d864f8c272ad>\u001b[0m in \u001b[0;36mmake_xy\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnext_chars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, Y = make_xy(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.2769\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"et-seasoned showers are to the ground; A\"\n",
      "et-seasoned showers are to the ground; And the thes the that the sores the the thin the that thou the here the the sing the ther the ther that the sorere the the thes the ther the ther the that the the that the sore the sing the sorere the heres the ther sore the the serer the thou ind the sore the sorthes the sthe here the the the the sore the the ther ther the the serer thou the then the here the the wore the that the wire the thet th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"et-seasoned showers are to the ground; A\"\n",
      "et-seasoned showers are to the ground; And me thee thee and thou porert wind shath routh al the lore the sheven thou hor sereres fore I lous th than th thal seweren tirhe this yris the serthen for thare forer dof tous whar the sares ard bith tho ghath the serter beath will thrn weee bedins the rerind thes thou bout weds alith lo fouthe are thil then bore fore the this sine woun thy lond thet and the sire thar ghe shind thith ther thor t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"et-seasoned showers are to the ground; A\"\n",
      "et-seasoned showers are to the ground; Ac memabs thek nechon tor’ ddert isv’fenred int that mevery zhati santcenetun on tey phatebs athe char thes I doos hall. 1 whove I thoue, gha limy lo bravrus Ipily thtu bave’st, nfor as ’ilhy yor have, Thes tias ke thirh thes hars nore rin bere than tlel’verar fooy lfrecpesti.n’ LhWesteel, Whe py bmoss or teas hitsiivenc’sseset sar. th me beasexe thith maves yufe fllos peanghy lo? heleise in yosale\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"et-seasoned showers are to the ground; A\"\n",
      "et-seasoned showers are to the ground; An luchelf iPphaun pryyhbvunfpting I hy par veuthde dllv veamesI : wfaeed’ctr rheres hat snuin suinby an faray n. For; thith th pesbricned sy the lits shate douguyd chil. hf wh mprve thekr Onwhe dewirn thar ifoss, andy by drthetdcrsind mas eate foutigy Note uf ill, whre hisusty mosth trit yo’us heal rppon isld aross.0 As Lathetxrithy thamgsypye h ougmenvAnd Whe molloushather, tptherb1 the daairs wo\n",
      "31384/31384 [==============================] - 69s 2ms/sample - loss: 2.2769\n",
      "Epoch 2/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.2000\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"here it lies, Yet what the best is, take\"\n",
      "here it lies, Yet what the best is, take the that south the seare, The the the ther wind the ther seat the ther sart the seath the ther seath the seath the the ther the pare the the ther or art are the ther with the seath the ther searse the ther and art and and and are the ther seare, The the ther are the seare the then the serer the the dore are the thes or the ther the seath the seath the ther with the seart and are in the seres, The\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"here it lies, Yet what the best is, take\"\n",
      "here it lies, Yet what the best is, take thin sore sater the thint thes beat, The the fard beerte to oll, Are non that toule: And ail mea, And ther and are whant dor than to thaes and the allserees the are thave bether, And the my ast and ant arse, An that the ming, Thou I to meast tot thin thy ferind are tho deded, And weat ere gor wing the ding the sors, Tho avert the thace beate dof alf in wine ary fereth, An the seart, And wilt ould\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"here it lies, Yet what the best is, take\"\n",
      "here it lies, Yet what the best is, take. O4 Wii harpy, Nouls leltest anow all ow ovlacg, Ir ie tee setury bides, Teolo’s forprreing, OTh ebads wy mee s faprf fotr plevew d.d if imemy prost, srembpre, Tith they diir: Ar tho moredig d?l, pgrevertd Ofireros’, Bnen af ire lipry if toc; Theof iglith beart’sthus uilu to ley . Tha amy iteun sinol, Thanl raverednrdmen yof whom hocore toris,, Hnw thot daat sord. B thoin hou Lerve fous, 1s Anlut\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"here it lies, Yet what the best is, take\"\n",
      "here it lies, Yet what the best is, taked andear I all s arsgf ind cutved ce maved, h afprerot, 1ne Bath woneupeer wsmses, rwoslit theeno t om, :id( ’wahr eisgsst, weive n ifveept shaar’. meM fanll fijre spaye , itert See. O4r0be. F1H efar o dofesy, And is tiy gh tpeveesontran isif ypilt:ize igrevy. Thrspry mpant ore, wanpar’s, drouled in at trpatd heee, Lhetd pirestoid,., O2 in momy ropvesrt;y, Be Lllikes: farlo os braveme,u IWive soup\n",
      "31384/31384 [==============================] - 69s 2ms/sample - loss: 2.2002\n",
      "Epoch 3/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.1395\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ot my amiss, Lest guilty of my faults th\"\n",
      "ot my amiss, Lest guilty of my faults the seate in the the seare the seat the seate the seare do love the me the seat the seat the seas in the seald do the the seat, The the the seat the seat the seat the seat the beat the sere the sing and and and and and and and seat and and and and and and and the sind and the seast to the seat the seat the thee the seand the sere the seat the the seat the seat the seat the seast and and and and and \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ot my amiss, Lest guilty of my faults th\"\n",
      "ot my amiss, Lest guilty of my faults the seathy now fore the my ind ind or warps and the hid to that tho live imy wot yous sond an the erass do fore whe sere, That seat ing my ast in s all tho gher dowh do the sond, For that by the gien so mere are than the serist wor bee the inge ho dinet and ars tre thou thon meast my my bed and, The love seare, To the the are so thou dade tou beace, An the hare send thy deale of are the sors tile th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ot my amiss, Lest guilty of my faults th\"\n",
      "ot my amiss, Lest guilty of my faults thy ous fourser, The wealgs art ngat hom meeds fureg a he kalled on athor beatrts And blised or tey wout dowe poife aps ars of eull code, kTist prandw, Sin meity eneie, No thes hour beake: Sr mey yick tho wirs, My aivee: yo haiik, Soee enes snow bredenty pner of list, 1vrWed rothr woore, Whon in alt yons ar tars Anls in dee youe sroae, ,y wot tiy seake st ileveers aprard nongor I deated, On ate lilc\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ot my amiss, Lest guilty of my faults th\"\n",
      "ot my amiss, Lest guilty of my faults thy gatat,. 1 inur dait, Saas elaate rot,. 1Whif ekyast, lhbe tyy ifyomy In seee: 6ioud ye yis our Woogs ao-, covith bone, h oil, 1iy gye seatlavo? wher Oa ait thuo an? thele, Ye tyem Tott reave wnept orrowak mo oid bom thounda, Thy fem sod tay non tr binds ois worm ankt. An ho  eosf my clovss yos wiis onle. Han yeuch ppave?xd file. The whicste cod thepiith erees. Le8r amr meq arn aums ant baet apli\n",
      "31384/31384 [==============================] - 68s 2ms/sample - loss: 2.1394\n",
      "Epoch 4/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.0890\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ot married to my muse, And therefore may\"\n",
      "ot married to my muse, And therefore may so the the the the south the sust the thes be the the the the seath the with thee the with the shath the the sting, The wing the wirt the the sing the the sure the thound the seath the with the seath the sof the my be the pore the seate the thes sore, The heat the seath the with the seath the sore the fore this the south the seath seath the sere the the suth the with the shes stound the seath the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ot married to my muse, And therefore may\"\n",
      "ot married to my muse, And therefore maye brenge the thing thes of moust thing thal soogh the will the diden mo mish these thee thes pouth bo the with seeind or inghes are suthes sues the my sed bue meast, And seat dos my auth sowen beate do pind ho hing. Whe the shath to in the sing, ble the the thend, And my thee thane ow oud, The love the suth be bus sure thous wors of love dend thou no the then to lon the the meses in the hath that \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ot married to my muse, And therefore may\"\n",
      "ot married to my muse, And therefore may llone: geceds ng’rign the to the nu. mon somgntowth theus, Tay thes ond bkemhimy seen or bt loy Whend ceoutir aigrtrdogh antsingn mo ghin’ bearime po nederingt, pheavet defill, divo ontor thatos or mallsve bes daty doo love, Dear if if love, of anm ildave, Noo  ofubepre, mouribe in mo sare Thightelive the byeis, Ar dast lirev, oon heo supe yhagr whes mo livee thiset. Yor wyikser his paroficd sove\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ot married to my muse, And therefore may\"\n",
      "ot married to my muse, And therefore may fraves’s. I (that ligh worsm. Anc thigd woath. hant stearts daingave, ikd pith ulle: To moreor: Lo gey whes dowh,’W apaitstey ks veve. Melngydtelifh’s mo eho. : shot thil, I feeded hedstrmusurlets ni lavusasha’su sum gusmig, snou, mave tisl. But  hapmius: Theounk’ sinn? aa, wand theper-hois bosp. Ands beakt, c, roveauped loig doulg, That boutrseilh bo hiinentt mo’s, Iy qume, ye, froveire foullw. \n",
      "31384/31384 [==============================] - 70s 2ms/sample - loss: 2.0892\n",
      "Epoch 5/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.0473\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ung with the trophies of my lovers gone,\"\n",
      "ung with the trophies of my lovers gone, The the seart seart ou thee wire thee or me are and the seare, And the the mear seath the sime wore thee sore seare the seate the sore the sore. The wirt that shat the seath the seare, And the wire the seath the meare the seath the seat so me beare, When the hath the are thee sore thee sore the seart, The thes are the south thee are thee or meare, The heart that thee are thee thas of meast in my \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ung with the trophies of my lovers gone,\"\n",
      "ung with the trophies of my lovers gone, What the buar in tho hast and so meres dore ghed sease, Then the prast of that love part the meart are pore to thep my beared bith thy some of my seake. The shand sulls that than thas theis fore thes hare I fare, Bit the heast the hart the wrill yous are fore fore, And wirt shath whest in seatseres are and antinge tise dorine the heat dere, Whith the mear do beast lof soor to cearing, And shine t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ung with the trophies of my lovers gone,\"\n",
      "ung with the trophies of my lovers gone, Whe mo ameme heve arasey batigees on chours bils yausu hath see.: 14urS wheco dorbtins stom, ’reverting, Fallecans gonlet’s of yone ioge to mine heor, The I wtoul fall siod, Wor me thou my piic teos bory if ardat cese: And thrumyse illevestwarfd ohs aise my I brid op cionstrabd sordos, Bu myuse’s sexin for, loffire, Then purresins fa hor in maveO thece forgoford inist to meeaenl’f. whtide hoth, w\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ung with the trophies of my lovers gone,\"\n",
      "ung with the trophies of my lovers gone, nom are uratre’cs my teredigr, Wiod mathy hus aveMy thakeowe shrish I  afenmI honder: ar in the beas, in tile taise IpeI Bite; Nof conine taice, 1ot agrkefandt cees snoshiminh giine omg ilmees hefrI Wheegd, sivo heings Whily dase, in matilit the thae. Pcames ow lved way. sho thy nowhind sutd fimeos dorfwige shephadg forcore, Whean ’hoh saee, lovgak thougnt if ayemine hame: adl wger, Bugt tha sorh\n",
      "31384/31384 [==============================] - 70s 2ms/sample - loss: 2.0472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1cd8481320>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
